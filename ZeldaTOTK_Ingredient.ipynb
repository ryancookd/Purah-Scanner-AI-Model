{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UIUIfDNktFcCyQ2dtRHlIhaf3jllcTWJ",
      "authorship_tag": "ABX9TyOzE5zJkq/0rr8iB3O0d5wi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryancookd/PurahScanner/blob/main/ZeldaTOTK_Ingredient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an experimental Zelda ToTK Ingredient Scanner"
      ],
      "metadata": {
        "id": "bWEnyc8VWoHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTS"
      ],
      "metadata": {
        "id": "dp30gdH4W2OE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "K3-kfWFNP1_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 28\n",
        "img_width = 28\n",
        "batch_size = 2\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Input((28, 28, 1)),\n",
        "    layers.Conv2D(16, 3, padding ='same'),\n",
        "    layers.Conv2D(32, 3, padding='same'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10),\n",
        "])"
      ],
      "metadata": {
        "id": "Lm8KuXxvYsNE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Training and Validation Sets From Data"
      ],
      "metadata": {
        "id": "mWu2STnKkGhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/ZeldaTOTK Ingredients',\n",
        "    labels='inferred',\n",
        "    label_mode = \"int\",\n",
        "    color_mode = 'grayscale',\n",
        "    batch_size = batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset = \"training\",\n",
        ")\n",
        "\n",
        "ds_validate = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/ZeldaTOTK Ingredients',\n",
        "    labels='inferred',\n",
        "    label_mode = \"int\",\n",
        "    color_mode = 'grayscale',\n",
        "    batch_size = batch_size,\n",
        "    image_size=(img_height, img_width),\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset = \"validation\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2HBI6RQZuP3",
        "outputId": "636f709f-8755-4b17-b609-bfb86f346098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 files belonging to 4 classes.\n",
            "Using 16 files for training.\n",
            "Found 20 files belonging to 4 classes.\n",
            "Using 4 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling Time Boys"
      ],
      "metadata": {
        "id": "S7mCA61HmUZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment(x, y):\n",
        "  image = tf.image.random_brightness(x, max_delta=0.05)\n",
        "  return image, y\n",
        "\n",
        "ds_train = ds_train.map(augment)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=[\n",
        "        keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    ],\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(ds_train, epochs=5, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxhB5B8fk1N4",
        "outputId": "ecafcf65-af7e-4d1d-da6c-6455cf10af6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "8/8 - 4s - loss: 90.8205 - accuracy: 0.1875 - 4s/epoch - 484ms/step\n",
            "Epoch 2/5\n",
            "8/8 - 0s - loss: 26.1427 - accuracy: 0.5625 - 197ms/epoch - 25ms/step\n",
            "Epoch 3/5\n",
            "8/8 - 0s - loss: 11.3670 - accuracy: 0.5625 - 194ms/epoch - 24ms/step\n",
            "Epoch 4/5\n",
            "8/8 - 0s - loss: 2.4751 - accuracy: 0.8750 - 98ms/epoch - 12ms/step\n",
            "Epoch 5/5\n",
            "8/8 - 0s - loss: 0.2060 - accuracy: 0.9375 - 102ms/epoch - 13ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x797291e66da0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(ds_validate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAbm2KRDr6UE",
        "outputId": "8767317c-6677-4fa7-acba-34f152ad3399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 8ms/step - loss: 5.0601 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.060115814208984, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the File to Keras"
      ],
      "metadata": {
        "id": "EnXCLh5ERc4f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI1YvCDFzpl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1ac463-47c8-48e2-ccf3-34a655564d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                62730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 67,530\n",
            "Trainable params: 67,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Save the entire model as a `.keras` zip archive.\n",
        "model.save('my_model.keras')\n",
        "\n",
        "new_model = tf.keras.models.load_model('my_model.keras')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to tfLite"
      ],
      "metadata": {
        "id": "L45vLILNhWGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISVFLioKhZi9",
        "outputId": "d50fdd69-81fa-42f7-b593-691b78068489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    }
  ]
}